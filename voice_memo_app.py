import streamlit as st
import tempfile
import os
import re
import json
from pathlib import Path
from datetime import datetime
import subprocess
from openai import OpenAI

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒšãƒ¼ã‚¸è¨­å®š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="éŸ³å£°ãƒ¡ãƒ¢ã‚¢ãƒ—ãƒª Pro",
    page_icon="ğŸ™ï¸",
    layout="wide"
)

if "api_key" not in st.session_state:
    st.session_state.api_key = ""
if "results" not in st.session_state:
    st.session_state.results = []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# éŸ³å£°å‡¦ç†
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def compress_audio(input_path, output_path):
    try:
        subprocess.run(
            ["ffmpeg", "-i", input_path, "-vn", "-ac", "1",
             "-ar", "16000", "-b:a", "32k", "-y", output_path],
            check=True, capture_output=True
        )
        return True
    except Exception as e:
        st.error(f"åœ§ç¸®ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def split_audio(input_path, chunk_sec=600):
    chunks = []
    try:
        probe = subprocess.run(
            ["ffprobe", "-v", "error", "-show_entries", "format=duration",
             "-of", "default=noprint_wrappers=1:nokey=1", input_path],
            capture_output=True, text=True, check=True
        )
        duration = float(probe.stdout.strip())
        num = int(duration / chunk_sec) + 1
        for i in range(num):
            out = input_path.replace(Path(input_path).suffix, f"_chunk{i}.mp3")
            subprocess.run(
                ["ffmpeg", "-i", input_path,
                 "-ss", str(i * chunk_sec), "-t", str(chunk_sec),
                 "-c", "copy", "-y", out],
                check=True, capture_output=True
            )
            if os.path.exists(out) and os.path.getsize(out) > 1000:
                chunks.append(out)
    except Exception as e:
        st.error(f"åˆ†å‰²ã‚¨ãƒ©ãƒ¼: {e}")
    return chunks


def transcribe_audio(file_path, api_key):
    """1ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—ï¼ˆå¤§å®¹é‡å¯¾å¿œï¼‰"""
    client = OpenAI(api_key=api_key)
    max_size = 24 * 1024 * 1024
    try:
        work_path = file_path
        if os.path.getsize(file_path) > max_size:
            st.info("  ğŸ”§ åœ§ç¸®ä¸­...")
            comp = file_path.replace(Path(file_path).suffix, "_comp.mp3")
            if not compress_audio(file_path, comp):
                return None
            work_path = comp

        if os.path.getsize(work_path) > max_size:
            st.info("  âœ‚ï¸ åˆ†å‰²ä¸­...")
            chunks = split_audio(work_path)
            if not chunks:
                return None
            texts = []
            pb = st.progress(0)
            for i, chunk in enumerate(chunks):
                with open(chunk, "rb") as f:
                    r = client.audio.transcriptions.create(
                        model="whisper-1", file=f, language="ja")
                    texts.append(r.text)
                pb.progress((i + 1) / len(chunks))
                os.remove(chunk)
            if work_path != file_path and os.path.exists(work_path):
                os.remove(work_path)
            return " ".join(texts).strip()

        with open(work_path, "rb") as f:
            r = client.audio.transcriptions.create(
                model="whisper-1", file=f, language="ja")
        if work_path != file_path and os.path.exists(work_path):
            os.remove(work_path)
        return r.text
    except Exception as e:
        st.error(f"æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {e}")
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# è³‡æ–™ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def extract_pdf_text(file_path):
    try:
        import pdfplumber
        texts = []
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages:
                t = page.extract_text()
                if t:
                    texts.append(t)
        return "\n".join(texts)
    except Exception:
        try:
            from pypdf import PdfReader
            reader = PdfReader(file_path)
            return "\n".join(p.extract_text() or "" for p in reader.pages)
        except Exception as e:
            return f"[PDFèª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {e}]"


def extract_pptx_text(file_path):
    try:
        from pptx import Presentation
        prs = Presentation(file_path)
        texts = []
        for i, slide in enumerate(prs.slides, 1):
            parts = [s.text.strip() for s in slide.shapes
                     if hasattr(s, "text") and s.text.strip()]
            if parts:
                texts.append(f"ã€ã‚¹ãƒ©ã‚¤ãƒ‰{i}ã€‘\n" + "\n".join(parts))
        return "\n\n".join(texts)
    except Exception as e:
        return f"[PPTXèª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {e}]"


def extract_docx_text(file_path):
    try:
        from docx import Document
        doc = Document(file_path)
        return "\n".join(p.text for p in doc.paragraphs if p.text.strip())
    except Exception as e:
        return f"[DOCXèª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {e}]"


def extract_material_text(uploaded_file):
    suffix = Path(uploaded_file.name).suffix.lower()
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as f:
        f.write(uploaded_file.read())
        tmp = f.name
    try:
        if suffix == ".pdf":
            return extract_pdf_text(tmp)
        elif suffix in [".pptx", ".ppt"]:
            return extract_pptx_text(tmp)
        elif suffix in [".docx", ".doc"]:
            return extract_docx_text(tmp)
        return f"[æœªå¯¾å¿œå½¢å¼: {suffix}]"
    finally:
        if os.path.exists(tmp):
            os.remove(tmp)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GPTï¼šPlaudé¢¨ãƒ¬ãƒãƒ¼ãƒˆ
# ï¼ˆè¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®çµåˆãƒ†ã‚­ã‚¹ãƒˆã‚’å—ã‘å–ã‚‹ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def generate_report(combined_transcript, file_labels, material_text, api_key):
    """
    combined_transcript : å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆã—ãŸæ–‡å­—èµ·ã“ã—
    file_labels         : ["file1.mp3", "file2.mp3", ...] ãƒ•ã‚¡ã‚¤ãƒ«åãƒªã‚¹ãƒˆ
    """
    client = OpenAI(api_key=api_key)

    files_note = (
        f"â€» æœ¬ãƒ¬ãƒãƒ¼ãƒˆã¯ä»¥ä¸‹ {len(file_labels)} ä»¶ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµ±åˆã—ãŸå†…å®¹ã§ã™ï¼š\n"
        + "\n".join(f"  - {l}" for l in file_labels)
        if len(file_labels) > 1 else ""
    )

    mat = ""
    if material_text and material_text.strip():
        mat = f"""
---
ã€è£œè¶³è³‡æ–™ã€‘
{material_text[:4000]}
---
ä¸Šè¨˜è³‡æ–™ã®æ•°å€¤ãƒ»å›ºæœ‰åè©ãƒ»ç”¨èªã‚’ç©æ¥µçš„ã«æ´»ç”¨ã—ã¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""

    prompt = f"""ä»¥ä¸‹ã®éŸ³å£°æ–‡å­—èµ·ã“ã—ã‹ã‚‰è©³ç´°ãªæ§‹é€ åŒ–ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
{files_note}
{mat}
ã€æ–‡å­—èµ·ã“ã—ï¼ˆå…¨ãƒ•ã‚¡ã‚¤ãƒ«çµ±åˆï¼‰ã€‘
{combined_transcript}

# ğŸ“ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼
ï¼ˆæ ¸å¿ƒã‚’æ‰ãˆãŸ2ã€œ3æ®µè½ã€‚æœ€é‡è¦ãªæ´å¯Ÿãƒ»çµè«–ã‚’å«ã‚ã‚‹ï¼‰

# ğŸ¯ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ
ï¼ˆ5ã€œ10å€‹ã®å…·ä½“çš„ãªé‡è¦ãƒã‚¤ãƒ³ãƒˆã€‚å„ãƒã‚¤ãƒ³ãƒˆã¯æ–‡è„ˆã‚’å«ã‚ã‚‹ï¼‰

# ğŸ’¡ ä¸»è¦ãªæ´å¯Ÿã¨åˆ†æ
ï¼ˆ3ã€œ5å€‹ã®æ·±ã„æ´å¯Ÿã€‚ãªãœé‡è¦ã‹ãƒ»ã©ã‚“ãªæ„å‘³ãŒã‚ã‚‹ã‹ã‚’èª¬æ˜ï¼‰

# âœ… ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ 
ï¼ˆå®Ÿè¡Œå¯èƒ½ãªå…·ä½“çš„ã‚¿ã‚¹ã‚¯ã‚’å„ªå…ˆåº¦ä»˜ãã§åˆ—æŒ™ã€‚èª°ãŒãƒ»ä½•ã‚’ãƒ»ã„ã¤ã¾ã§ã«ï¼‰

# ğŸ—£ï¸ é‡è¦ãªç™ºè¨€ãƒ»å¼•ç”¨
ï¼ˆç‰¹ã«é‡è¦ãªç™ºè¨€ã‚’3ã€œ5å€‹æŠœç²‹ã€‚æ–‡è„ˆã¨å…±ã«ï¼‰

# ğŸ“Š ãƒˆãƒ”ãƒƒã‚¯åˆ¥è©³ç´°åˆ†æ
ï¼ˆä¸»è¦ãƒˆãƒ”ãƒƒã‚¯ã”ã¨ã«è©³ã—ãåˆ†æã€‚æ±ºå®šäº‹é …ãƒ»æ‡¸å¿µç‚¹ãªã©ï¼‰

# ğŸ”„ ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—äº‹é …
ï¼ˆä»Šå¾Œã®ç¢ºèªäº‹é …ãƒ»æœªè§£æ±ºã®å•é¡Œãƒ»æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼‰

# ğŸ“Œ ãƒ¡ã‚¿æƒ…å ±
- éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(file_labels)}ä»¶
- å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(file_labels)}
- è£œè¶³è³‡æ–™: {"ã‚ã‚Šï¼ˆå†…å®¹ã‚’åæ˜ æ¸ˆã¿ï¼‰" if material_text else "ãªã—"}
- ç·Šæ€¥åº¦: [é«˜/ä¸­/ä½]

â€»æ–‡å­—èµ·ã“ã—ã«ãªã„æƒ…å ±ã¯ã€Œè¨€åŠãªã—ã€ã¨è¨˜è¼‰ã€‚"""

    try:
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯éŸ³å£°ãƒ¡ãƒ¢ã‹ã‚‰é«˜å“è³ªãªæ§‹é€ åŒ–ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        return resp.choices[0].message.content
    except Exception as e:
        st.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GPTï¼šæ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ï¼ˆJSONï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def generate_summary_json(combined_transcript, report, material_text, api_key):
    client = OpenAI(api_key=api_key)
    mat_note = "è£œè¶³è³‡æ–™ã®æƒ…å ±ã‚‚åæ˜ ã—ã¦ãã ã•ã„ã€‚" if material_text else ""
    prompt = f"""ä»¥ä¸‹ã®éŸ³å£°æ–‡å­—èµ·ã“ã—ã¨ãƒ¬ãƒãƒ¼ãƒˆã‹ã‚‰ã€æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ã‚’JSONå½¢å¼ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚{mat_note}

ã€æ–‡å­—èµ·ã“ã—ï¼ˆæŠœç²‹ï¼‰ã€‘
{combined_transcript[:2500]}

ã€ãƒ¬ãƒãƒ¼ãƒˆï¼ˆæŠœç²‹ï¼‰ã€‘
{report[:3000]}

ä»¥ä¸‹ã®JSONæ§‹é€ ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆæ—¥æœ¬èªã§ï¼‰ã€‚
ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆ```ï¼‰ã¯ä½¿ã‚ãšã€JSONã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

{{
  "title": "ä¼šè­°ãƒ»ãƒ¡ãƒ¢ã®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆ15ã€œ30æ–‡å­—ï¼‰",
  "date": "æ¨å®šæ—¥ä»˜ã¾ãŸã¯ã€Œä¸æ˜ã€",
  "type": "ä¼šè­° / 1on1 / ãƒ–ãƒ¬ã‚¹ãƒˆ / è¬›ç¾© / ãã®ä»–",
  "duration": "æ¨å®šXXåˆ†",
  "urgency": "é«˜ / ä¸­ / ä½",
  "one_line": "ã“ã®ä¼šè­°ãƒ»ãƒ¡ãƒ¢ã‚’ä¸€æ–‡ã§è¡¨ã™ã¨ï¼ˆ30ã€œ50æ–‡å­—ï¼‰",
  "participants": ["å‚åŠ è€…1", "å‚åŠ è€…2"],
  "flow": [
    {{"time": "åºç›¤", "topic": "ãƒˆãƒ”ãƒƒã‚¯å", "summary": "å†…å®¹ã®è¦ç´„ï¼ˆ30ã€œ60æ–‡å­—ï¼‰"}},
    {{"time": "ä¸­ç›¤", "topic": "ãƒˆãƒ”ãƒƒã‚¯å", "summary": "å†…å®¹ã®è¦ç´„ï¼ˆ30ã€œ60æ–‡å­—ï¼‰"}},
    {{"time": "çµ‚ç›¤", "topic": "ãƒˆãƒ”ãƒƒã‚¯å", "summary": "å†…å®¹ã®è¦ç´„ï¼ˆ30ã€œ60æ–‡å­—ï¼‰"}}
  ],
  "decisions": [
    {{"title": "æ±ºå®šäº‹é …å", "detail": "è©³ç´°èª¬æ˜"}}
  ],
  "actions": [
    {{"priority": "é«˜/ä¸­/ä½", "who": "æ‹…å½“è€…", "what": "ã‚¿ã‚¹ã‚¯å†…å®¹", "when": "æœŸé™"}}
  ],
  "concerns": [
    {{"title": "æ‡¸å¿µãƒ»ãƒªã‚¹ã‚¯å", "detail": "è©³ç´°èª¬æ˜"}}
  ],
  "next_topics": ["æ¬¡å›ä»¥é™ã®æ¤œè¨äº‹é …1", "æ¬¡å›ä»¥é™ã®æ¤œè¨äº‹é …2"],
  "key_numbers": [
    {{"label": "æŒ‡æ¨™åãƒ»æ•°å€¤å", "value": "å…·ä½“çš„ãªæ•°å€¤ãƒ»ãƒ‡ãƒ¼ã‚¿"}}
  ],
  "keywords": ["é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", "é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3", "é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰4", "é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰5"]
}}

æ³¨æ„ï¼š
- decisionsã¯å®Ÿéš›ã«æ±ºå®šã—ãŸã“ã¨ã®ã¿ã€‚ãªã‘ã‚Œã°ç©ºé…åˆ—[]
- actionsã¯å…·ä½“çš„ãªã‚¿ã‚¹ã‚¯ã€‚ãªã‘ã‚Œã°ç©ºé…åˆ—[]
- concernsã¯ãƒªã‚¹ã‚¯ãƒ»æ‡¸å¿µãƒ»æœªè§£æ±ºäº‹é …ã€‚ãªã‘ã‚Œã°ç©ºé…åˆ—[]
- key_numbersã¯å…·ä½“çš„ãªæ•°å€¤ãŒè¨€åŠã•ã‚ŒãŸå ´åˆã®ã¿ã€‚ãªã‘ã‚Œã°ç©ºé…åˆ—[]
"""
    try:
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ä¼šè­°ã®å†…å®¹ã‚’æ­£ç¢ºã«æ§‹é€ åŒ–ã™ã‚‹ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚æŒ‡ç¤ºé€šã‚Šã®JSONã®ã¿ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            response_format={"type": "json_object"}
        )
        return json.loads(resp.choices[0].message.content)
    except Exception as e:
        st.error(f"æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ â†’ HTML
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def summary_to_html(data, file_labels, generated_at):
    urgency_color = {"é«˜": "#e53e5a", "ä¸­": "#f5a623", "ä½": "#22c38e"}.get(data.get("urgency", "ä¸­"), "#888")
    urgency_bg    = {"é«˜": "#fff0f2", "ä¸­": "#fff8ee", "ä½": "#f0fff8"}.get(data.get("urgency", "ä¸­"), "#f5f5f5")

    # ãƒ•ãƒ­ãƒ¼
    flow_items = data.get("flow", [])
    flow_html = ""
    for i, f in enumerate(flow_items):
        connector = '<div class="flow-arrow">â†“</div>' if i < len(flow_items) - 1 else ""
        flow_html += f"""
        <div class="flow-item">
          <div class="flow-time">{f.get('time','')}</div>
          <div class="flow-content">
            <div class="flow-topic">{f.get('topic','')}</div>
            <div class="flow-summary">{f.get('summary','')}</div>
          </div>
        </div>{connector}"""

    # æ±ºå®šäº‹é …
    decisions = data.get("decisions", [])
    dec_html = "".join(
        f'<div class="card-item card-decision"><div class="card-item-title">âœ… {d.get("title","")}</div><div class="card-item-detail">{d.get("detail","")}</div></div>'
        for d in decisions
    ) if decisions else '<div class="empty-note">è¨€åŠãªã—</div>'

    # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
    actions = data.get("actions", [])
    pc_map = {"é«˜": "#e53e5a", "ä¸­": "#f5a623", "ä½": "#22c38e"}
    act_html = "".join(
        f'''<div class="action-row">
          <span class="action-priority" style="background:{pc_map.get(a.get("priority","ä¸­"),"#888")}20;color:{pc_map.get(a.get("priority","ä¸­"),"#888")};border:1px solid {pc_map.get(a.get("priority","ä¸­"),"#888")}40">{a.get("priority","")}</span>
          <div class="action-body">
            <div class="action-what">{a.get("what","")}</div>
            <div class="action-meta">ğŸ‘¤ {a.get("who","æœªå®š")} &nbsp;ï½œ&nbsp; ğŸ“… {a.get("when","æœŸé™æœªå®š")}</div>
          </div>
        </div>'''
        for a in sorted(actions, key=lambda x: {"é«˜":0,"ä¸­":1,"ä½":2}.get(x.get("priority","ä¸­"),1))
    ) if actions else '<div class="empty-note">è¨€åŠãªã—</div>'

    # æ‡¸å¿µ
    concerns = data.get("concerns", [])
    con_html = "".join(
        f'<div class="card-item card-concern"><div class="card-item-title">âš ï¸ {c.get("title","")}</div><div class="card-item-detail">{c.get("detail","")}</div></div>'
        for c in concerns
    ) if concerns else '<div class="empty-note">è¨€åŠãªã—</div>'

    # æ¬¡å›
    nexts = data.get("next_topics", [])
    next_html = "".join(f"<li>{n}</li>" for n in nexts) if nexts else '<li class="empty-note">è¨€åŠãªã—</li>'

    # æ•°å€¤
    nums = data.get("key_numbers", [])
    num_html = "".join(
        f'<div class="kpi-card"><div class="kpi-value">{n.get("value","")}</div><div class="kpi-label">{n.get("label","")}</div></div>'
        for n in nums
    )

    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
    keywords = data.get("keywords", [])
    kw_html = "".join(f'<span class="keyword">{k}</span>' for k in keywords)

    # å‚åŠ è€…
    participants = data.get("participants", [])
    par_html = "ãƒ»".join(participants) if participants else "ä¸æ˜"

    # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§
    files_html = "ãƒ»".join(file_labels)

    return f"""<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>{data.get('title','æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼')}</title>
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@300;400;500;700;900&display=swap');
:root {{
  --ink:#1a2140;--ink2:#4a567a;--ink3:#8892b0;
  --line:#e2e8f0;--bg:#f8faff;--card:#ffffff;
  --blue:#3b6ef0;--blue-lt:#eef2ff;
  --green:#22c38e;--red:#e53e5a;--amber:#f5a623;
  --radius:10px;--shadow:0 2px 12px rgba(26,33,64,.08);
}}
*{{box-sizing:border-box;margin:0;padding:0;}}
body{{font-family:'Noto Sans JP',sans-serif;background:var(--bg);color:var(--ink);font-size:14px;line-height:1.7;}}
.page{{max-width:860px;margin:0 auto;padding:40px 32px 80px;}}
.doc-header{{border-bottom:3px solid var(--blue);padding-bottom:24px;margin-bottom:32px;}}
.doc-meta{{display:flex;gap:10px;flex-wrap:wrap;margin-bottom:12px;}}
.meta-chip{{display:inline-flex;align-items:center;gap:5px;font-size:11px;font-weight:600;letter-spacing:.06em;color:var(--ink3);background:white;border:1px solid var(--line);border-radius:99px;padding:3px 11px;}}
.doc-title{{font-size:clamp(20px,3vw,28px);font-weight:900;color:var(--ink);line-height:1.3;margin-bottom:12px;}}
.one-line{{font-size:14px;color:var(--ink2);background:var(--blue-lt);border-left:4px solid var(--blue);padding:10px 16px;border-radius:0 8px 8px 0;font-weight:500;}}
.urgency-badge{{display:inline-flex;align-items:center;gap:5px;font-size:12px;font-weight:700;padding:4px 14px;border-radius:99px;background:{urgency_bg};color:{urgency_color};border:1.5px solid {urgency_color}40;margin-top:12px;}}
.kpi-row{{display:flex;gap:12px;flex-wrap:wrap;margin-bottom:32px;}}
.kpi-card{{background:var(--card);border:1px solid var(--line);border-radius:var(--radius);padding:16px 20px;min-width:120px;text-align:center;box-shadow:var(--shadow);flex:1;}}
.kpi-value{{font-size:22px;font-weight:900;color:var(--blue);line-height:1.2;}}
.kpi-label{{font-size:11px;color:var(--ink3);margin-top:4px;}}
.section{{margin-bottom:32px;}}
.section-title{{font-size:11px;font-weight:800;letter-spacing:.14em;text-transform:uppercase;color:var(--blue);margin-bottom:12px;display:flex;align-items:center;gap:8px;}}
.section-title::after{{content:'';flex:1;height:1px;background:var(--line);}}
.flow-wrap{{display:flex;flex-direction:column;}}
.flow-item{{display:flex;gap:16px;align-items:flex-start;background:var(--card);border:1px solid var(--line);border-radius:var(--radius);padding:14px 18px;width:100%;box-shadow:var(--shadow);}}
.flow-arrow{{text-align:center;color:var(--ink3);font-size:18px;padding:4px 0;}}
.flow-time{{font-size:11px;font-weight:700;color:var(--blue);background:var(--blue-lt);padding:3px 10px;border-radius:99px;white-space:nowrap;flex-shrink:0;align-self:flex-start;margin-top:2px;}}
.flow-topic{{font-size:14px;font-weight:700;color:var(--ink);margin-bottom:4px;}}
.flow-summary{{font-size:13px;color:var(--ink2);}}
.card-item{{background:var(--card);border-radius:var(--radius);padding:14px 18px;margin-bottom:10px;border:1px solid var(--line);box-shadow:var(--shadow);}}
.card-decision{{border-left:4px solid var(--green);}}
.card-concern{{border-left:4px solid var(--amber);}}
.card-item-title{{font-size:14px;font-weight:700;color:var(--ink);margin-bottom:4px;}}
.card-item-detail{{font-size:13px;color:var(--ink2);}}
.action-row{{display:flex;gap:14px;align-items:flex-start;background:var(--card);border:1px solid var(--line);border-radius:var(--radius);padding:12px 16px;margin-bottom:8px;box-shadow:var(--shadow);}}
.action-priority{{font-size:11px;font-weight:700;padding:3px 10px;border-radius:99px;white-space:nowrap;flex-shrink:0;}}
.action-what{{font-size:14px;font-weight:600;color:var(--ink);margin-bottom:4px;}}
.action-meta{{font-size:12px;color:var(--ink3);}}
.next-list{{list-style:none;display:flex;flex-direction:column;gap:8px;}}
.next-list li{{background:var(--card);border:1px solid var(--line);border-radius:var(--radius);padding:10px 16px;font-size:13px;color:var(--ink2);box-shadow:var(--shadow);}}
.next-list li::before{{content:"â†’ ";color:var(--blue);font-weight:700;}}
.keyword-wrap{{display:flex;flex-wrap:wrap;gap:8px;}}
.keyword{{background:var(--blue-lt);color:var(--blue);border:1px solid #c0cef8;border-radius:99px;padding:4px 14px;font-size:12px;font-weight:600;}}
.two-col{{display:grid;grid-template-columns:1fr 1fr;gap:24px;}}
.empty-note{{font-size:13px;color:var(--ink3);font-style:italic;padding:8px 4px;}}
.doc-footer{{margin-top:48px;padding-top:16px;border-top:1px solid var(--line);font-size:11px;color:var(--ink3);}}
.files-note{{font-size:12px;color:var(--ink3);margin-top:4px;}}
@media(max-width:600px){{.page{{padding:24px 16px 60px;}}.two-col{{grid-template-columns:1fr;}}}}
@media print{{body{{background:white;}}.page{{padding:20px;max-width:100%;}}.card-item,.action-row,.flow-item,.next-list li{{-webkit-print-color-adjust:exact;print-color-adjust:exact;break-inside:avoid;}}.section{{break-inside:avoid;}}}}
</style>
</head>
<body>
<div class="page">
  <div class="doc-header">
    <div class="doc-meta">
      <span class="meta-chip">ğŸ“… {data.get('date','ä¸æ˜')}</span>
      <span class="meta-chip">ğŸ™ï¸ {data.get('type','ä¼šè­°')}</span>
      <span class="meta-chip">â± {data.get('duration','ä¸æ˜')}</span>
      <span class="meta-chip">ğŸ‘¥ {par_html}</span>
    </div>
    <div class="doc-title">{data.get('title','æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼')}</div>
    <div class="one-line">{data.get('one_line','')}</div>
    <div class="urgency-badge">{'ğŸ”´' if data.get('urgency')=='é«˜' else 'ğŸŸ¡' if data.get('urgency')=='ä¸­' else 'ğŸŸ¢'} ç·Šæ€¥åº¦ï¼š{data.get('urgency','ä¸­')}</div>
    <div class="files-note">ğŸ“ å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ï¼š{files_html}</div>
  </div>

  {"<div class='kpi-row'>" + num_html + "</div>" if nums else ""}

  <div class="section">
    <div class="section-title">ğŸ“‹ è©±ã®æµã‚Œãƒ»æ§‹æˆ</div>
    <div class="flow-wrap">{flow_html}</div>
  </div>

  <div class="two-col">
    <div class="section">
      <div class="section-title">âœ… æ±ºå®šäº‹é …</div>
      {dec_html}
    </div>
    <div class="section">
      <div class="section-title">âš ï¸ æ‡¸å¿µãƒ»ãƒªã‚¹ã‚¯</div>
      {con_html}
    </div>
  </div>

  <div class="section">
    <div class="section-title">ğŸ¯ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ </div>
    {act_html}
  </div>

  <div class="section">
    <div class="section-title">ğŸ”„ æ¬¡å›ä»¥é™ã®æ¤œè¨äº‹é …</div>
    <ul class="next-list">{next_html}</ul>
  </div>

  {"<div class='section'><div class='section-title'>ğŸ· ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰</div><div class='keyword-wrap'>" + kw_html + "</div></div>" if keywords else ""}

  <div class="doc-footer">
    <div>ğŸ“ {files_html}</div>
    <div>ğŸ• ç”Ÿæˆæ—¥æ™‚ï¼š{generated_at}</div>
  </div>
</div>
</body>
</html>"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# UIï¼šã‚µã‚¤ãƒ‰ãƒãƒ¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    api_key = st.text_input(
        "OpenAI APIã‚­ãƒ¼", type="password",
        value=st.session_state.api_key
    )
    if api_key:
        st.session_state.api_key = api_key
        st.success("âœ“ APIã‚­ãƒ¼è¨­å®šæ¸ˆã¿")

    st.divider()
    st.markdown("""
### ğŸ“‹ å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼
**ğŸµ éŸ³å£°ï¼ˆè¤‡æ•°å¯ï¼‰**
MP3 / WAV / M4A / WebM

**ğŸ“„ è£œè¶³è³‡æ–™ï¼ˆä»»æ„ãƒ»è¤‡æ•°å¯ï¼‰**
PDF / PPTX / DOCX

### ğŸ“¤ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
| | å†…å®¹ |
|---|---|
| .txt | æ–‡å­—èµ·ã“ã— |
| .md | è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ |
| .html | æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ |
""")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# UIï¼šãƒ¡ã‚¤ãƒ³
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.title("ğŸ™ï¸ éŸ³å£°ãƒ¡ãƒ¢ã‚¢ãƒ—ãƒª Pro")
st.caption("è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ« â†’ çµ±åˆãƒ¬ãƒãƒ¼ãƒˆ ï¼ PDFãƒ»PPTXè£œå®Œ ï¼ Plaudé¢¨ãƒ¬ãƒãƒ¼ãƒˆ ï¼ æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼")

if not st.session_state.api_key:
    st.warning("âš ï¸ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§OpenAI APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
    st.stop()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â‘¢ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒªã‚¢ï¼šç¸¦ä¸¦ã³
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.subheader("ğŸµ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰")
st.caption("è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã¯è‡ªå‹•çš„ã«ãƒ•ã‚¡ã‚¤ãƒ«åé †ï¼ˆä½œæˆæ—¥æ™‚é †ï¼‰ã§çµåˆã—ã€**1ã¤ã®ãƒ¬ãƒãƒ¼ãƒˆ**ã‚’ä½œæˆã—ã¾ã™ã€‚")
audio_files = st.file_uploader(
    "MP3ãƒ»WAVãƒ»M4Aãƒ»WebM",
    type=["mp3", "wav", "m4a", "webm"],
    accept_multiple_files=True,
    help="ãƒ•ã‚¡ã‚¤ãƒ«åã®æ•°å­—é †ã«è‡ªå‹•æ•´åˆ—ã—ã¦å‡¦ç†ã—ã¾ã™ã€‚"
)

st.markdown("---")

st.subheader("ğŸ“„ è£œè¶³è³‡æ–™ï¼ˆä»»æ„ãƒ»è¤‡æ•°å¯ï¼‰")
st.caption("ä¼šè­°è³‡æ–™ãƒ»ã‚¹ãƒ©ã‚¤ãƒ‰ãªã©ã€‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ãƒ¬ãƒãƒ¼ãƒˆã®ç²¾åº¦ãŒä¸ŠãŒã‚Šã¾ã™ã€‚**ãªãã¦ã‚‚å‹•ä½œã—ã¾ã™ã€‚**")
material_files = st.file_uploader(
    "PDFãƒ»PPTXãƒ»DOCX",
    type=["pdf", "pptx", "ppt", "docx", "doc"],
    accept_multiple_files=True,
    help="è³‡æ–™ãªã—ã§ã‚‚å‡¦ç†ã§ãã¾ã™ã€‚"
)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèªè¡¨ç¤º
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if audio_files:
    def sort_key(f):
        nums = re.findall(r'\d+', f.name)
        return "".join(nums).zfill(20) if nums else f.name

    sorted_audio = sorted(audio_files, key=sort_key)

    st.markdown("---")

    # å‡¦ç†äºˆå®šä¸€è¦§
    with st.expander(f"ğŸ“‹ å‡¦ç†äºˆå®šï¼šéŸ³å£° {len(sorted_audio)}ä»¶ï¼ˆçµåˆã—ã¦1ã¤ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆï¼‰", expanded=True):
        total_mb = sum(f.size for f in sorted_audio) / (1024 * 1024)
        for i, f in enumerate(sorted_audio, 1):
            mb = f.size / (1024 * 1024)
            c1, c2, c3 = st.columns([5, 2, 2])
            c1.write(f"**{i}.** {f.name}")
            c2.caption(f"{mb:.1f} MB")
            c3.caption("ğŸ”§ è¦åœ§ç¸®" if mb > 24 else "âœ… OK")
        st.caption(f"åˆè¨ˆï¼š{total_mb:.1f} MB")

        if len(sorted_audio) > 1:
            st.info(f"ğŸ’¡ {len(sorted_audio)}ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é †ç•ªã«æ–‡å­—èµ·ã“ã—ã—ã€**ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ**ã—ã¦ã‹ã‚‰1ã¤ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚")

    if material_files:
        st.info(f"ğŸ“ è£œè¶³è³‡æ–™ï¼ˆ{len(material_files)}ä»¶ï¼‰: {', '.join(f.name for f in material_files)}")
    else:
        st.caption("ğŸ“ è£œè¶³è³‡æ–™ãªã—")

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # â‘¡ ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ ï¼‹ å‡¦ç†é–‹å§‹ãƒœã‚¿ãƒ³
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    st.markdown("---")
    btn_col1, btn_col2 = st.columns([1, 1])

    with btn_col1:
        if st.button("ğŸ—‘ï¸ å‡¦ç†çµæœã‚’ã‚¯ãƒªã‚¢", use_container_width=True):
            st.session_state.results = []
            st.success("âœ… ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã§ãã¾ã™ã€‚")
            st.rerun()

    with btn_col2:
        run = st.button("ğŸš€ å‡¦ç†é–‹å§‹", type="primary", use_container_width=True)

    if run:
        # â”€â”€ è³‡æ–™ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º â”€â”€
        combined_material = None
        if material_files:
            with st.spinner("ğŸ“„ è£œè¶³è³‡æ–™ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                mat_texts = []
                for mf in material_files:
                    t = extract_material_text(mf)
                    if t and not t.startswith("["):
                        mat_texts.append(f"=== {mf.name} ===\n{t}")
                    else:
                        st.warning(f"âš ï¸ {mf.name}: {t}")
            if mat_texts:
                combined_material = "\n\n".join(mat_texts)
                st.success(f"âœ… è³‡æ–™ {len(mat_texts)}ä»¶ èª­ã¿è¾¼ã¿å®Œäº†")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # â‘  å„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å€‹åˆ¥ã«æ–‡å­—èµ·ã“ã— â†’ çµåˆ
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        st.markdown("---")
        st.markdown("### ğŸ§ ã‚¹ãƒ†ãƒƒãƒ—1ï¼šæ–‡å­—èµ·ã“ã—")

        transcripts_per_file = {}   # {filename: transcript}
        all_tmp_paths = []

        for idx, audio_file in enumerate(sorted_audio):
            st.markdown(f"**[{idx+1}/{len(sorted_audio)}]** {audio_file.name}")

            suffix = Path(audio_file.name).suffix
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as f:
                f.write(audio_file.read())
                tmp_path = f.name
                all_tmp_paths.append(tmp_path)

            with st.spinner(f"  æ–‡å­—èµ·ã“ã—ä¸­..."):
                transcript = transcribe_audio(tmp_path, st.session_state.api_key)

            if transcript:
                transcripts_per_file[audio_file.name] = transcript
                st.success(f"  âœ… å®Œäº†ï¼ˆ{len(transcript):,}æ–‡å­—ï¼‰")
            else:
                st.error(f"  âŒ å¤±æ•—")

        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        for p in all_tmp_paths:
            if os.path.exists(p):
                os.remove(p)

        if not transcripts_per_file:
            st.error("æ–‡å­—èµ·ã“ã—ã«æˆåŠŸã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            st.stop()

        # â”€â”€ ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ãƒ¼ä»˜ãï¼‰ â”€â”€
        file_labels = list(transcripts_per_file.keys())

        if len(file_labels) == 1:
            combined_transcript = list(transcripts_per_file.values())[0]
        else:
            parts = []
            for fname, tr in transcripts_per_file.items():
                parts.append(f"--- {fname} ---\n{tr}")
            combined_transcript = "\n\n".join(parts)

        st.success(f"âœ… {len(file_labels)}ä»¶ æ–‡å­—èµ·ã“ã—å®Œäº†ï¼ˆåˆè¨ˆ {len(combined_transcript):,}æ–‡å­—ï¼‰")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆçµåˆãƒ†ã‚­ã‚¹ãƒˆã§1æœ¬ï¼‰
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        st.markdown("### ğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—2ï¼šçµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")

        with st.spinner("GPT-4o ã§ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­..."):
            report = generate_report(
                combined_transcript, file_labels, combined_material, st.session_state.api_key
            )

        if not report:
            st.error("ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            st.stop()

        mat_note = "ï¼ˆè³‡æ–™è£œå®Œã‚ã‚Šï¼‰" if combined_material else ""
        st.success(f"âœ… ãƒ¬ãƒãƒ¼ãƒˆå®Œäº† {mat_note}")

        # â”€â”€ æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ç”Ÿæˆ â”€â”€
        st.markdown("### ğŸ“‹ ã‚¹ãƒ†ãƒƒãƒ—3ï¼šæ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ç”Ÿæˆ")

        with st.spinner("æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ç”Ÿæˆä¸­..."):
            summary_data = generate_summary_json(
                combined_transcript, report, combined_material, st.session_state.api_key
            )

        summary_html = None
        if summary_data:
            generated_at = datetime.now().strftime("%Y-%m-%d %H:%M")
            summary_html = summary_to_html(summary_data, file_labels, generated_at)
            st.success("âœ… æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼å®Œäº†")

        # â”€â”€ çµæœã‚’ä¿å­˜ â”€â”€
        result = {
            "label": "ãƒ»".join(file_labels),
            "file_labels": file_labels,
            "date": datetime.now().strftime("%Y-%m-%d %H:%M"),
            "transcripts_per_file": transcripts_per_file,
            "combined_transcript": combined_transcript,
            "report": report,
            "summary_html": summary_html,
            "has_material": combined_material is not None
        }

        st.session_state.results = [result] + st.session_state.results
        st.balloons()
        st.success("ğŸ‰ å‡¦ç†å®Œäº†ï¼")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# çµæœè¡¨ç¤º
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if st.session_state.results:
    st.markdown("---")

    # ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ï¼ˆçµæœã‚¨ãƒªã‚¢ä¸Šéƒ¨ã«ã‚‚é…ç½®ï¼‰
    hcol1, hcol2 = st.columns([4, 1])
    hcol1.header(f"ğŸ“‹ å‡¦ç†çµæœï¼ˆ{len(st.session_state.results)}ä»¶ï¼‰")
    if hcol2.button("ğŸ—‘ï¸ å…¨ã‚¯ãƒªã‚¢", key="clear_top"):
        st.session_state.results = []
        st.rerun()

    for result in st.session_state.results:
        mat_badge = "  ğŸ“ è³‡æ–™è£œå®Œã‚ã‚Š" if result["has_material"] else ""
        n_files = len(result["file_labels"])
        header_label = (
            f"ğŸ“ {result['label']}  â€”  {result['date']}{mat_badge}"
            if n_files == 1
            else f"ğŸ“ [{n_files}ä»¶çµ±åˆ] {result['label']}  â€”  {result['date']}{mat_badge}"
        )

        with st.expander(header_label, expanded=True):
            tab_labels = ["ğŸ“„ æ–‡å­—èµ·ã“ã—", "ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆ"]
            if result.get("summary_html"):
                tab_labels.append("ğŸ“‹ æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼")
            tabs = st.tabs(tab_labels)

            # æ–‡å­—èµ·ã“ã—ã‚¿ãƒ–ï¼šãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«è¡¨ç¤º
            with tabs[0]:
                if n_files > 1:
                    # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ã‚µãƒ–ã‚¿ãƒ–ã§åˆ‡ã‚Šæ›¿ãˆ
                    sub_labels = list(result["transcripts_per_file"].keys()) + ["ğŸ“„ å…¨æ–‡ï¼ˆçµåˆï¼‰"]
                    sub_tabs = st.tabs(sub_labels)
                    for i, (fname, tr) in enumerate(result["transcripts_per_file"].items()):
                        with sub_tabs[i]:
                            st.text_area("", tr, height=220,
                                         key=f"tr_{result['date']}_{fname}")
                            st.download_button(
                                f"ğŸ“¥ {fname} æ–‡å­—èµ·ã“ã— (.txt)",
                                tr,
                                file_name=f"transcript_{Path(fname).stem}.txt",
                                mime="text/plain",
                                key=f"dtr_{result['date']}_{fname}"
                            )
                    with sub_tabs[-1]:
                        st.text_area("", result["combined_transcript"], height=300,
                                     key=f"tr_all_{result['date']}")
                        st.download_button(
                            "ğŸ“¥ å…¨æ–‡å­—èµ·ã“ã—ï¼ˆçµåˆï¼‰(.txt)",
                            result["combined_transcript"],
                            file_name=f"transcript_combined_{result['date'].replace(':','').replace(' ','_')}.txt",
                            mime="text/plain",
                            key=f"dtr_all_{result['date']}"
                        )
                else:
                    fname = result["file_labels"][0]
                    tr = result["transcripts_per_file"][fname]
                    st.text_area("", tr, height=250,
                                 key=f"tr_{result['date']}_{fname}")
                    st.download_button(
                        "ğŸ“¥ æ–‡å­—èµ·ã“ã— (.txt)",
                        tr,
                        file_name=f"transcript_{Path(fname).stem}.txt",
                        mime="text/plain",
                        key=f"dtr_{result['date']}_{fname}"
                    )

            # ãƒ¬ãƒãƒ¼ãƒˆã‚¿ãƒ–
            with tabs[1]:
                if result["report"]:
                    st.markdown(result["report"])
                    fname_base = (
                        Path(result["file_labels"][0]).stem if n_files == 1
                        else f"combined_{result['date'].replace(':','').replace(' ','_')}"
                    )
                    st.download_button(
                        "ğŸ“¥ ãƒ¬ãƒãƒ¼ãƒˆ (.md)",
                        result["report"],
                        file_name=f"report_{fname_base}.md",
                        mime="text/markdown",
                        key=f"drp_{result['date']}"
                    )

            # æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ã‚¿ãƒ–
            if result.get("summary_html") and len(tabs) > 2:
                with tabs[2]:
                    st.info("ğŸ’¡ ã€ŒHTMLã§ä¿å­˜ã€ã—ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ãã¨ã€è¦‹ã‚„ã™ãå°åˆ·ãƒ»PDFåŒ–ã§ãã¾ã™ã€‚")
                    fname_base = (
                        Path(result["file_labels"][0]).stem if n_files == 1
                        else f"combined_{result['date'].replace(':','').replace(' ','_')}"
                    )
                    st.download_button(
                        "ğŸ“¥ æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ (.html)",
                        result["summary_html"],
                        file_name=f"summary_{fname_base}.html",
                        mime="text/html",
                        key=f"dsum_{result['date']}"
                    )
                    with st.expander("ğŸ” ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆã‚¢ãƒ—ãƒªå†…ï¼‰"):
                        st.components.v1.html(result["summary_html"], height=800, scrolling=True)

st.markdown("---")
st.caption("ğŸ™ï¸ éŸ³å£°ãƒ¡ãƒ¢ã‚¢ãƒ—ãƒª Pro ï¼ Powered by OpenAI Whisper & GPT-4o")
