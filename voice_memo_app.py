import streamlit as st
import tempfile
import os
import re
import json
from pathlib import Path
from datetime import datetime
import subprocess
from openai import OpenAI

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ãƒšãƒ¼ã‚¸è¨­å®š
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="éŸ³å£°ãƒ¡ãƒ¢ã‚¢ãƒ—ãƒª Pro",
    page_icon="ğŸ™ï¸",
    layout="wide"
)

if "api_key" not in st.session_state:
    st.session_state.api_key = ""
if "results" not in st.session_state:
    st.session_state.results = []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# éŸ³å£°å‡¦ç†
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def compress_audio(input_path, output_path):
    try:
        subprocess.run(
            ["ffmpeg", "-i", input_path, "-vn", "-ac", "1",
             "-ar", "16000", "-b:a", "32k", "-y", output_path],
            check=True, capture_output=True
        )
        return True
    except Exception as e:
        st.error(f"åœ§ç¸®ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def split_audio(input_path, chunk_sec=600):
    chunks = []
    try:
        probe = subprocess.run(
            ["ffprobe", "-v", "error", "-show_entries", "format=duration",
             "-of", "default=noprint_wrappers=1:nokey=1", input_path],
            capture_output=True, text=True, check=True
        )
        duration = float(probe.stdout.strip())
        num = int(duration / chunk_sec) + 1
        for i in range(num):
            out = input_path.replace(Path(input_path).suffix, f"_chunk{i}.mp3")
            subprocess.run(
                ["ffmpeg", "-i", input_path,
                 "-ss", str(i * chunk_sec), "-t", str(chunk_sec),
                 "-c", "copy", "-y", out],
                check=True, capture_output=True
            )
            if os.path.exists(out) and os.path.getsize(out) > 1000:
                chunks.append(out)
    except Exception as e:
        st.error(f"åˆ†å‰²ã‚¨ãƒ©ãƒ¼: {e}")
    return chunks


def transcribe_audio(file_path, api_key):
    client = OpenAI(api_key=api_key)
    max_size = 24 * 1024 * 1024
    try:
        work_path = file_path
        if os.path.getsize(file_path) > max_size:
            st.info("ğŸ”§ åœ§ç¸®ä¸­...")
            comp = file_path.replace(Path(file_path).suffix, "_comp.mp3")
            if not compress_audio(file_path, comp):
                return None
            work_path = comp

        if os.path.getsize(work_path) > max_size:
            st.info("âœ‚ï¸ åˆ†å‰²ä¸­...")
            chunks = split_audio(work_path)
            if not chunks:
                return None
            texts = []
            pb = st.progress(0)
            for i, chunk in enumerate(chunks):
                with open(chunk, "rb") as f:
                    r = client.audio.transcriptions.create(
                        model="whisper-1", file=f, language="ja")
                    texts.append(r.text)
                pb.progress((i + 1) / len(chunks))
                os.remove(chunk)
            if work_path != file_path and os.path.exists(work_path):
                os.remove(work_path)
            return " ".join(texts).strip()

        with open(work_path, "rb") as f:
            r = client.audio.transcriptions.create(
                model="whisper-1", file=f, language="ja")
        if work_path != file_path and os.path.exists(work_path):
            os.remove(work_path)
        return r.text
    except Exception as e:
        st.error(f"æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {e}")
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# è³‡æ–™ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def extract_pdf_text(file_path):
    try:
        import pdfplumber
        texts = []
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages:
                t = page.extract_text()
                if t:
                    texts.append(t)
        return "\n".join(texts)
    except Exception:
        try:
            from pypdf import PdfReader
            reader = PdfReader(file_path)
            return "\n".join(p.extract_text() or "" for p in reader.pages)
        except Exception as e:
            return f"[PDFèª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {e}]"


def extract_pptx_text(file_path):
    try:
        from pptx import Presentation
        prs = Presentation(file_path)
        texts = []
        for i, slide in enumerate(prs.slides, 1):
            parts = [s.text.strip() for s in slide.shapes
                     if hasattr(s, "text") and s.text.strip()]
            if parts:
                texts.append(f"ã€ã‚¹ãƒ©ã‚¤ãƒ‰{i}ã€‘\n" + "\n".join(parts))
        return "\n\n".join(texts)
    except Exception as e:
        return f"[PPTXèª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {e}]"


def extract_docx_text(file_path):
    try:
        from docx import Document
        doc = Document(file_path)
        return "\n".join(p.text for p in doc.paragraphs if p.text.strip())
    except Exception as e:
        return f"[DOCXèª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {e}]"


def extract_material_text(uploaded_file):
    suffix = Path(uploaded_file.name).suffix.lower()
    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as f:
        f.write(uploaded_file.read())
        tmp = f.name
    try:
        if suffix == ".pdf":
            return extract_pdf_text(tmp)
        elif suffix in [".pptx", ".ppt"]:
            return extract_pptx_text(tmp)
        elif suffix in [".docx", ".doc"]:
            return extract_docx_text(tmp)
        return f"[æœªå¯¾å¿œå½¢å¼: {suffix}]"
    finally:
        if os.path.exists(tmp):
            os.remove(tmp)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GPTï¼šPlaudé¢¨ãƒ¬ãƒãƒ¼ãƒˆ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def generate_report(transcript, material_text, api_key):
    client = OpenAI(api_key=api_key)
    mat = ""
    if material_text and material_text.strip():
        mat = f"""
---
ã€è£œè¶³è³‡æ–™ã€‘
{material_text[:4000]}
---
ä¸Šè¨˜è³‡æ–™ã®æ•°å€¤ãƒ»å›ºæœ‰åè©ãƒ»ç”¨èªã‚’ç©æ¥µçš„ã«æ´»ç”¨ã—ã¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
    prompt = f"""ä»¥ä¸‹ã®éŸ³å£°æ–‡å­—èµ·ã“ã—ã‹ã‚‰è©³ç´°ãªæ§‹é€ åŒ–ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
{mat}
ã€æ–‡å­—èµ·ã“ã—ã€‘
{transcript}

# ğŸ“ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼
ï¼ˆæ ¸å¿ƒã‚’æ‰ãˆãŸ2ã€œ3æ®µè½ã€‚æœ€é‡è¦ãªæ´å¯Ÿãƒ»çµè«–ã‚’å«ã‚ã‚‹ï¼‰

# ğŸ¯ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ
ï¼ˆ5ã€œ10å€‹ã®å…·ä½“çš„ãªé‡è¦ãƒã‚¤ãƒ³ãƒˆã€‚å„ãƒã‚¤ãƒ³ãƒˆã¯æ–‡è„ˆã‚’å«ã‚ã‚‹ï¼‰

# ğŸ’¡ ä¸»è¦ãªæ´å¯Ÿã¨åˆ†æ
ï¼ˆ3ã€œ5å€‹ã®æ·±ã„æ´å¯Ÿã€‚ãªãœé‡è¦ã‹ãƒ»ã©ã‚“ãªæ„å‘³ãŒã‚ã‚‹ã‹ã‚’èª¬æ˜ï¼‰

# âœ… ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ 
ï¼ˆå®Ÿè¡Œå¯èƒ½ãªå…·ä½“çš„ã‚¿ã‚¹ã‚¯ã‚’å„ªå…ˆåº¦ä»˜ãã§åˆ—æŒ™ã€‚èª°ãŒãƒ»ä½•ã‚’ãƒ»ã„ã¤ã¾ã§ã«ï¼‰

# ğŸ—£ï¸ é‡è¦ãªç™ºè¨€ãƒ»å¼•ç”¨
ï¼ˆç‰¹ã«é‡è¦ãªç™ºè¨€ã‚’3ã€œ5å€‹æŠœç²‹ã€‚æ–‡è„ˆã¨å…±ã«ï¼‰

# ğŸ“Š ãƒˆãƒ”ãƒƒã‚¯åˆ¥è©³ç´°åˆ†æ
ï¼ˆä¸»è¦ãƒˆãƒ”ãƒƒã‚¯ã”ã¨ã«è©³ã—ãåˆ†æã€‚æ±ºå®šäº‹é …ãƒ»æ‡¸å¿µç‚¹ãªã©ï¼‰

# ğŸ”„ ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—äº‹é …
ï¼ˆä»Šå¾Œã®ç¢ºèªäº‹é …ãƒ»æœªè§£æ±ºã®å•é¡Œãƒ»æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼‰

# ğŸ“Œ ãƒ¡ã‚¿æƒ…å ±
- æ¨å®šæ‰€è¦æ™‚é–“: [Xåˆ†]
- ä¸»è¦å‚åŠ è€…/è©±è€…: [æ¨å®š]
- ä¼šè­°/ãƒ¡ãƒ¢ã®ã‚¿ã‚¤ãƒ—: [æ¨å®š]
- ç·Šæ€¥åº¦: [é«˜/ä¸­/ä½]
- è£œè¶³è³‡æ–™: {"ã‚ã‚Šï¼ˆå†…å®¹ã‚’åæ˜ æ¸ˆã¿ï¼‰" if material_text else "ãªã—"}

â€»æ–‡å­—èµ·ã“ã—ã«ãªã„æƒ…å ±ã¯ã€Œè¨€åŠãªã—ã€ã¨è¨˜è¼‰ã€‚"""

    try:
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯éŸ³å£°ãƒ¡ãƒ¢ã‹ã‚‰é«˜å“è³ªãªæ§‹é€ åŒ–ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        return resp.choices[0].message.content
    except Exception as e:
        st.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GPTï¼šæ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ï¼ˆJSONï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def generate_summary_json(transcript, report, material_text, api_key):
    """
    GPT-4oã«JSONå½¢å¼ã§æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆã•ã›ã‚‹ã€‚
    è¿”ã‚Šå€¤: dict or None
    """
    client = OpenAI(api_key=api_key)

    mat_note = "è£œè¶³è³‡æ–™ã®æƒ…å ±ã‚‚åæ˜ ã—ã¦ãã ã•ã„ã€‚" if material_text else ""

    prompt = f"""ä»¥ä¸‹ã®éŸ³å£°æ–‡å­—èµ·ã“ã—ã¨ãƒ¬ãƒãƒ¼ãƒˆã‹ã‚‰ã€æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ã‚’JSONå½¢å¼ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚{mat_note}

ã€æ–‡å­—èµ·ã“ã—ï¼ˆæŠœç²‹ï¼‰ã€‘
{transcript[:2500]}

ã€ãƒ¬ãƒãƒ¼ãƒˆï¼ˆæŠœç²‹ï¼‰ã€‘
{report[:3000]}

ä»¥ä¸‹ã®JSONæ§‹é€ ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆæ—¥æœ¬èªã§ï¼‰ã€‚
ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ï¼ˆ```ï¼‰ã¯ä½¿ã‚ãšã€JSONã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

{{
  "title": "ä¼šè­°ãƒ»ãƒ¡ãƒ¢ã®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆ15ã€œ30æ–‡å­—ï¼‰",
  "date": "æ¨å®šæ—¥ä»˜ã¾ãŸã¯ã€Œä¸æ˜ã€",
  "type": "ä¼šè­° / 1on1 / ãƒ–ãƒ¬ã‚¹ãƒˆ / è¬›ç¾© / ãã®ä»–",
  "duration": "æ¨å®šXXåˆ†",
  "urgency": "é«˜ / ä¸­ / ä½",
  "one_line": "ã“ã®ä¼šè­°ãƒ»ãƒ¡ãƒ¢ã‚’ä¸€æ–‡ã§è¡¨ã™ã¨ï¼ˆ30ã€œ50æ–‡å­—ï¼‰",
  "participants": ["å‚åŠ è€…1", "å‚åŠ è€…2"],
  "flow": [
    {{"time": "åºç›¤", "topic": "ãƒˆãƒ”ãƒƒã‚¯å", "summary": "å†…å®¹ã®è¦ç´„ï¼ˆ30ã€œ60æ–‡å­—ï¼‰"}},
    {{"time": "ä¸­ç›¤", "topic": "ãƒˆãƒ”ãƒƒã‚¯å", "summary": "å†…å®¹ã®è¦ç´„ï¼ˆ30ã€œ60æ–‡å­—ï¼‰"}},
    {{"time": "çµ‚ç›¤", "topic": "ãƒˆãƒ”ãƒƒã‚¯å", "summary": "å†…å®¹ã®è¦ç´„ï¼ˆ30ã€œ60æ–‡å­—ï¼‰"}}
  ],
  "decisions": [
    {{"title": "æ±ºå®šäº‹é …å", "detail": "è©³ç´°èª¬æ˜"}},
    ...
  ],
  "actions": [
    {{"priority": "é«˜/ä¸­/ä½", "who": "æ‹…å½“è€…", "what": "ã‚¿ã‚¹ã‚¯å†…å®¹", "when": "æœŸé™"}},
    ...
  ],
  "concerns": [
    {{"title": "æ‡¸å¿µãƒ»ãƒªã‚¹ã‚¯å", "detail": "è©³ç´°èª¬æ˜"}},
    ...
  ],
  "next_topics": ["æ¬¡å›ä»¥é™ã®æ¤œè¨äº‹é …1", "æ¬¡å›ä»¥é™ã®æ¤œè¨äº‹é …2"],
  "key_numbers": [
    {{"label": "æŒ‡æ¨™åãƒ»æ•°å€¤å", "value": "å…·ä½“çš„ãªæ•°å€¤ãƒ»ãƒ‡ãƒ¼ã‚¿"}}
  ],
  "keywords": ["é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", "é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰3", "é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰4", "é‡è¦ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰5"]
}}

æ³¨æ„ï¼š
- decisionsã¯å®Ÿéš›ã«æ±ºå®šã—ãŸã“ã¨ã®ã¿ã€‚ãªã‘ã‚Œã°ç©ºé…åˆ—[]
- actionsã¯å…·ä½“çš„ãªã‚¿ã‚¹ã‚¯ã€‚ãªã‘ã‚Œã°ç©ºé…åˆ—[]
- concernsã¯ãƒªã‚¹ã‚¯ãƒ»æ‡¸å¿µãƒ»æœªè§£æ±ºäº‹é …ã€‚ãªã‘ã‚Œã°ç©ºé…åˆ—[]
- key_numbersã¯å…·ä½“çš„ãªæ•°å€¤ãŒè¨€åŠã•ã‚ŒãŸå ´åˆã®ã¿ã€‚ãªã‘ã‚Œã°ç©ºé…åˆ—[]
- æ–‡å­—èµ·ã“ã—ã«ãªã„æƒ…å ±ã¯æ¨æ¸¬ã›ãšçœç•¥ã™ã‚‹
"""

    try:
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯ä¼šè­°ã®å†…å®¹ã‚’æ­£ç¢ºã«æ§‹é€ åŒ–ã™ã‚‹ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚æŒ‡ç¤ºé€šã‚Šã®JSONã®ã¿ã‚’å‡ºåŠ›ã—ã¾ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            response_format={"type": "json_object"}
        )
        raw = resp.choices[0].message.content
        return json.loads(raw)
    except Exception as e:
        st.error(f"æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
        return None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ â†’ ç¾ã—ã„HTML
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def summary_to_html(data, source_filename, generated_at):
    """JSONãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å°åˆ·å¯¾å¿œã®æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼HTMLã‚’ç”Ÿæˆ"""

    urgency_color = {"é«˜": "#e53e5a", "ä¸­": "#f5a623", "ä½": "#22c38e"}.get(data.get("urgency", "ä¸­"), "#888")
    urgency_bg    = {"é«˜": "#fff0f2", "ä¸­": "#fff8ee", "ä½": "#f0fff8"}.get(data.get("urgency", "ä¸­"), "#f5f5f5")

    # â”€â”€ ãƒ•ãƒ­ãƒ¼å›³ â”€â”€
    flow_items = data.get("flow", [])
    flow_html = ""
    for i, f in enumerate(flow_items):
        connector = '<div class="flow-arrow">â†“</div>' if i < len(flow_items) - 1 else ""
        flow_html += f"""
        <div class="flow-item">
          <div class="flow-time">{f.get('time','')}</div>
          <div class="flow-content">
            <div class="flow-topic">{f.get('topic','')}</div>
            <div class="flow-summary">{f.get('summary','')}</div>
          </div>
        </div>{connector}"""

    # â”€â”€ æ±ºå®šäº‹é … â”€â”€
    decisions = data.get("decisions", [])
    dec_html = ""
    if decisions:
        for d in decisions:
            dec_html += f"""
        <div class="card-item card-decision">
          <div class="card-item-title">âœ… {d.get('title','')}</div>
          <div class="card-item-detail">{d.get('detail','')}</div>
        </div>"""
    else:
        dec_html = '<div class="empty-note">è¨€åŠãªã—</div>'

    # â”€â”€ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ  â”€â”€
    actions = data.get("actions", [])
    act_html = ""
    if actions:
        priority_color = {"é«˜": "#e53e5a", "ä¸­": "#f5a623", "ä½": "#22c38e"}
        for a in sorted(actions, key=lambda x: {"é«˜":0,"ä¸­":1,"ä½":2}.get(x.get("priority","ä¸­"),1)):
            pc = priority_color.get(a.get("priority","ä¸­"), "#888")
            act_html += f"""
        <div class="action-row">
          <span class="action-priority" style="background:{pc}20;color:{pc};border:1px solid {pc}40">{a.get('priority','')}</span>
          <div class="action-body">
            <div class="action-what">{a.get('what','')}</div>
            <div class="action-meta">ğŸ‘¤ {a.get('who','æœªå®š')} &nbsp;ï½œ&nbsp; ğŸ“… {a.get('when','æœŸé™æœªå®š')}</div>
          </div>
        </div>"""
    else:
        act_html = '<div class="empty-note">è¨€åŠãªã—</div>'

    # â”€â”€ æ‡¸å¿µãƒ»ãƒªã‚¹ã‚¯ â”€â”€
    concerns = data.get("concerns", [])
    con_html = ""
    if concerns:
        for c in concerns:
            con_html += f"""
        <div class="card-item card-concern">
          <div class="card-item-title">âš ï¸ {c.get('title','')}</div>
          <div class="card-item-detail">{c.get('detail','')}</div>
        </div>"""
    else:
        con_html = '<div class="empty-note">è¨€åŠãªã—</div>'

    # â”€â”€ æ¬¡å›æ¤œè¨äº‹é … â”€â”€
    nexts = data.get("next_topics", [])
    next_html = "".join(f'<li>{n}</li>' for n in nexts) if nexts else '<li class="empty-note">è¨€åŠãªã—</li>'

    # â”€â”€ æ•°å€¤ãƒ‡ãƒ¼ã‚¿ â”€â”€
    nums = data.get("key_numbers", [])
    num_html = ""
    if nums:
        for n in nums:
            num_html += f"""
        <div class="kpi-card">
          <div class="kpi-value">{n.get('value','')}</div>
          <div class="kpi-label">{n.get('label','')}</div>
        </div>"""

    # â”€â”€ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ â”€â”€
    keywords = data.get("keywords", [])
    kw_html = "".join(f'<span class="keyword">{k}</span>' for k in keywords)

    # â”€â”€ å‚åŠ è€… â”€â”€
    participants = data.get("participants", [])
    par_html = "ãƒ»".join(participants) if participants else "ä¸æ˜"

    return f"""<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>{data.get('title','æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼')}</title>
<style>
@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+JP:wght@300;400;500;700;900&display=swap');

:root {{
  --ink:     #1a2140;
  --ink2:    #4a567a;
  --ink3:    #8892b0;
  --line:    #e2e8f0;
  --bg:      #f8faff;
  --card:    #ffffff;
  --blue:    #3b6ef0;
  --blue-lt: #eef2ff;
  --green:   #22c38e;
  --red:     #e53e5a;
  --amber:   #f5a623;
  --radius:  10px;
  --shadow:  0 2px 12px rgba(26,33,64,.08);
}}

* {{ box-sizing: border-box; margin: 0; padding: 0; }}

body {{
  font-family: 'Noto Sans JP', sans-serif;
  background: var(--bg);
  color: var(--ink);
  font-size: 14px;
  line-height: 1.7;
  padding: 0;
}}

/* â”€â”€ ãƒšãƒ¼ã‚¸ wrapper â”€â”€ */
.page {{
  max-width: 860px;
  margin: 0 auto;
  padding: 40px 32px 80px;
}}

/* â”€â”€ ãƒ˜ãƒƒãƒ€ãƒ¼ â”€â”€ */
.doc-header {{
  border-bottom: 3px solid var(--blue);
  padding-bottom: 24px;
  margin-bottom: 32px;
}}

.doc-meta {{
  display: flex;
  gap: 16px;
  flex-wrap: wrap;
  margin-bottom: 12px;
}}

.meta-chip {{
  display: inline-flex;
  align-items: center;
  gap: 5px;
  font-size: 11px;
  font-weight: 600;
  letter-spacing: .06em;
  color: var(--ink3);
  background: white;
  border: 1px solid var(--line);
  border-radius: 99px;
  padding: 3px 11px;
}}

.doc-title {{
  font-size: clamp(20px, 3vw, 28px);
  font-weight: 900;
  color: var(--ink);
  line-height: 1.3;
  margin-bottom: 12px;
}}

.one-line {{
  font-size: 14px;
  color: var(--ink2);
  background: var(--blue-lt);
  border-left: 4px solid var(--blue);
  padding: 10px 16px;
  border-radius: 0 8px 8px 0;
  font-weight: 500;
}}

.urgency-badge {{
  display: inline-flex;
  align-items: center;
  gap: 5px;
  font-size: 12px;
  font-weight: 700;
  padding: 4px 14px;
  border-radius: 99px;
  background: {urgency_bg};
  color: {urgency_color};
  border: 1.5px solid {urgency_color}40;
  margin-top: 12px;
}}

/* â”€â”€ KPIã‚«ãƒ¼ãƒ‰ â”€â”€ */
.kpi-row {{
  display: flex;
  gap: 12px;
  flex-wrap: wrap;
  margin-bottom: 32px;
}}

.kpi-card {{
  background: var(--card);
  border: 1px solid var(--line);
  border-radius: var(--radius);
  padding: 16px 20px;
  min-width: 120px;
  text-align: center;
  box-shadow: var(--shadow);
  flex: 1;
}}

.kpi-value {{
  font-size: 22px;
  font-weight: 900;
  color: var(--blue);
  line-height: 1.2;
}}

.kpi-label {{
  font-size: 11px;
  color: var(--ink3);
  margin-top: 4px;
}}

/* â”€â”€ ã‚»ã‚¯ã‚·ãƒ§ãƒ³ â”€â”€ */
.section {{
  margin-bottom: 32px;
}}

.section-title {{
  font-size: 11px;
  font-weight: 800;
  letter-spacing: .14em;
  text-transform: uppercase;
  color: var(--blue);
  margin-bottom: 12px;
  display: flex;
  align-items: center;
  gap: 8px;
}}

.section-title::after {{
  content: '';
  flex: 1;
  height: 1px;
  background: var(--line);
}}

/* â”€â”€ ãƒ•ãƒ­ãƒ¼ â”€â”€ */
.flow-wrap {{
  display: flex;
  flex-direction: column;
  align-items: flex-start;
  gap: 0;
}}

.flow-item {{
  display: flex;
  gap: 16px;
  align-items: flex-start;
  background: var(--card);
  border: 1px solid var(--line);
  border-radius: var(--radius);
  padding: 14px 18px;
  width: 100%;
  box-shadow: var(--shadow);
}}

.flow-arrow {{
  text-align: center;
  color: var(--ink3);
  font-size: 18px;
  padding: 4px 0;
  width: 100%;
}}

.flow-time {{
  font-size: 11px;
  font-weight: 700;
  color: var(--blue);
  background: var(--blue-lt);
  padding: 3px 10px;
  border-radius: 99px;
  white-space: nowrap;
  flex-shrink: 0;
  align-self: flex-start;
  margin-top: 2px;
}}

.flow-topic {{
  font-size: 14px;
  font-weight: 700;
  color: var(--ink);
  margin-bottom: 4px;
}}

.flow-summary {{
  font-size: 13px;
  color: var(--ink2);
}}

/* â”€â”€ ã‚«ãƒ¼ãƒ‰ã‚¢ã‚¤ãƒ†ãƒ  â”€â”€ */
.card-item {{
  background: var(--card);
  border-radius: var(--radius);
  padding: 14px 18px;
  margin-bottom: 10px;
  border: 1px solid var(--line);
  box-shadow: var(--shadow);
}}

.card-decision {{ border-left: 4px solid var(--green); }}
.card-concern  {{ border-left: 4px solid var(--amber); }}

.card-item-title {{
  font-size: 14px;
  font-weight: 700;
  color: var(--ink);
  margin-bottom: 4px;
}}

.card-item-detail {{
  font-size: 13px;
  color: var(--ink2);
}}

/* â”€â”€ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ  â”€â”€ */
.action-row {{
  display: flex;
  gap: 14px;
  align-items: flex-start;
  background: var(--card);
  border: 1px solid var(--line);
  border-radius: var(--radius);
  padding: 12px 16px;
  margin-bottom: 8px;
  box-shadow: var(--shadow);
}}

.action-priority {{
  font-size: 11px;
  font-weight: 700;
  padding: 3px 10px;
  border-radius: 99px;
  white-space: nowrap;
  flex-shrink: 0;
}}

.action-what {{
  font-size: 14px;
  font-weight: 600;
  color: var(--ink);
  margin-bottom: 4px;
}}

.action-meta {{
  font-size: 12px;
  color: var(--ink3);
}}

/* â”€â”€ æ¬¡å›æ¤œè¨ â”€â”€ */
.next-list {{
  list-style: none;
  display: flex;
  flex-direction: column;
  gap: 8px;
}}

.next-list li {{
  background: var(--card);
  border: 1px solid var(--line);
  border-radius: var(--radius);
  padding: 10px 16px;
  font-size: 13px;
  color: var(--ink2);
  box-shadow: var(--shadow);
}}

.next-list li::before {{ content: "â†’ "; color: var(--blue); font-weight: 700; }}

/* â”€â”€ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ â”€â”€ */
.keyword-wrap {{ display: flex; flex-wrap: wrap; gap: 8px; }}

.keyword {{
  background: var(--blue-lt);
  color: var(--blue);
  border: 1px solid #c0cef8;
  border-radius: 99px;
  padding: 4px 14px;
  font-size: 12px;
  font-weight: 600;
}}

/* â”€â”€ å‚åŠ è€… â”€â”€ */
.participant-bar {{
  background: var(--card);
  border: 1px solid var(--line);
  border-radius: var(--radius);
  padding: 12px 16px;
  font-size: 13px;
  color: var(--ink2);
  box-shadow: var(--shadow);
}}

.empty-note {{
  font-size: 13px;
  color: var(--ink3);
  font-style: italic;
  padding: 8px 4px;
}}

/* â”€â”€ ãƒ•ãƒƒã‚¿ãƒ¼ â”€â”€ */
.doc-footer {{
  margin-top: 48px;
  padding-top: 16px;
  border-top: 1px solid var(--line);
  display: flex;
  justify-content: space-between;
  font-size: 11px;
  color: var(--ink3);
}}

/* â”€â”€ 2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ â”€â”€ */
.two-col {{ display: grid; grid-template-columns: 1fr 1fr; gap: 24px; }}

@media (max-width: 600px) {{
  .page {{ padding: 24px 16px 60px; }}
  .two-col {{ grid-template-columns: 1fr; }}
}}

/* â”€â”€ å°åˆ· â”€â”€ */
@media print {{
  body {{ background: white; }}
  .page {{ padding: 20px; max-width: 100%; }}
  .card-item, .action-row, .flow-item, .next-list li {{
    -webkit-print-color-adjust: exact;
    print-color-adjust: exact;
    break-inside: avoid;
  }}
  .section {{ break-inside: avoid; }}
}}
</style>
</head>
<body>
<div class="page">

  <!-- ãƒ˜ãƒƒãƒ€ãƒ¼ -->
  <div class="doc-header">
    <div class="doc-meta">
      <span class="meta-chip">ğŸ“… {data.get('date','ä¸æ˜')}</span>
      <span class="meta-chip">ğŸ™ï¸ {data.get('type','ä¼šè­°')}</span>
      <span class="meta-chip">â± {data.get('duration','ä¸æ˜')}</span>
      <span class="meta-chip">ğŸ‘¥ {par_html}</span>
    </div>
    <div class="doc-title">{data.get('title','æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼')}</div>
    <div class="one-line">{data.get('one_line','')}</div>
    <div class="urgency-badge">{'ğŸ”´' if data.get('urgency')=='é«˜' else 'ğŸŸ¡' if data.get('urgency')=='ä¸­' else 'ğŸŸ¢'} ç·Šæ€¥åº¦ï¼š{data.get('urgency','ä¸­')}</div>
  </div>

  <!-- KPIæ•°å€¤ï¼ˆã‚ã‚Œã°ï¼‰ -->
  {"<div class='kpi-row'>" + num_html + "</div>" if nums else ""}

  <!-- è©±ã®æµã‚Œ -->
  <div class="section">
    <div class="section-title">ğŸ“‹ è©±ã®æµã‚Œãƒ»æ§‹æˆ</div>
    <div class="flow-wrap">{flow_html}</div>
  </div>

  <!-- æ±ºå®šäº‹é … ï¼† æ‡¸å¿µãƒ»ãƒªã‚¹ã‚¯ -->
  <div class="two-col">
    <div class="section">
      <div class="section-title">âœ… æ±ºå®šäº‹é …</div>
      {dec_html}
    </div>
    <div class="section">
      <div class="section-title">âš ï¸ æ‡¸å¿µãƒ»ãƒªã‚¹ã‚¯</div>
      {con_html}
    </div>
  </div>

  <!-- ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ  -->
  <div class="section">
    <div class="section-title">ğŸ¯ ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ </div>
    {act_html}
  </div>

  <!-- æ¬¡å›ä»¥é™ã®æ¤œè¨äº‹é … -->
  <div class="section">
    <div class="section-title">ğŸ”„ æ¬¡å›ä»¥é™ã®æ¤œè¨äº‹é …</div>
    <ul class="next-list">{next_html}</ul>
  </div>

  <!-- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ -->
  {"<div class='section'><div class='section-title'>ğŸ· ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰</div><div class='keyword-wrap'>" + kw_html + "</div></div>" if keywords else ""}

  <!-- ãƒ•ãƒƒã‚¿ãƒ¼ -->
  <div class="doc-footer">
    <span>ğŸ“ {source_filename}</span>
    <span>ğŸ• ç”Ÿæˆæ—¥æ™‚ï¼š{generated_at}</span>
  </div>

</div>
</body>
</html>"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# UIï¼šã‚µã‚¤ãƒ‰ãƒãƒ¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    api_key = st.text_input(
        "OpenAI APIã‚­ãƒ¼", type="password",
        value=st.session_state.api_key
    )
    if api_key:
        st.session_state.api_key = api_key
        st.success("âœ“ APIã‚­ãƒ¼è¨­å®šæ¸ˆã¿")

    st.divider()
    st.markdown("""
### ğŸ“‹ å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼
**ğŸµ éŸ³å£°ï¼ˆè¤‡æ•°å¯ï¼‰**
MP3 / WAV / M4A / WebM

**ğŸ“„ è£œè¶³è³‡æ–™ï¼ˆä»»æ„ãƒ»è¤‡æ•°å¯ï¼‰**
PDF / PPTX / DOCX

### ğŸ“¤ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«
| ãƒ•ã‚¡ã‚¤ãƒ« | å†…å®¹ |
|---|---|
| .txt | æ–‡å­—èµ·ã“ã— |
| .md | è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ |
| .html | æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ |
""")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# UIï¼šãƒ¡ã‚¤ãƒ³
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.title("ğŸ™ï¸ éŸ³å£°ãƒ¡ãƒ¢ã‚¢ãƒ—ãƒª Pro")
st.caption("è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œ ï¼ PDFãƒ»PPTXè£œå®Œ ï¼ Plaudé¢¨ãƒ¬ãƒãƒ¼ãƒˆ ï¼ æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ï¼ˆå°åˆ·å¯¾å¿œHTMLï¼‰")

if not st.session_state.api_key:
    st.warning("âš ï¸ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§OpenAI APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
    st.stop()

# â”€â”€ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒªã‚¢ â”€â”€
col1, col2 = st.columns([3, 2])

with col1:
    st.subheader("ğŸµ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰")
    audio_files = st.file_uploader(
        "MP3ãƒ»WAVãƒ»M4Aãƒ»WebM",
        type=["mp3", "wav", "m4a", "webm"],
        accept_multiple_files=True,
        help="ãƒ•ã‚¡ã‚¤ãƒ«åã®æ•°å­—é †ï¼ˆä½œæˆæ—¥æ™‚é †ï¼‰ã«è‡ªå‹•æ•´åˆ—ã—ã¦å‡¦ç†ã—ã¾ã™ã€‚"
    )

with col2:
    st.subheader("ğŸ“„ è£œè¶³è³‡æ–™ï¼ˆä»»æ„ï¼‰")
    st.caption("ä¼šè­°è³‡æ–™ãƒ»ã‚¹ãƒ©ã‚¤ãƒ‰ãªã©ã€‚ãªãã¦ã‚‚å‹•ä½œã—ã¾ã™ã€‚")
    material_files = st.file_uploader(
        "PDFãƒ»PPTXãƒ»DOCX",
        type=["pdf", "pptx", "ppt", "docx", "doc"],
        accept_multiple_files=True
    )

# â”€â”€ ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª â”€â”€
if audio_files:
    def sort_key(f):
        nums = re.findall(r'\d+', f.name)
        return "".join(nums).zfill(20) if nums else f.name

    sorted_audio = sorted(audio_files, key=sort_key)

    st.markdown("---")
    with st.expander(f"ğŸ“‹ å‡¦ç†äºˆå®šï¼šéŸ³å£° {len(sorted_audio)}ä»¶", expanded=True):
        for i, f in enumerate(sorted_audio, 1):
            mb = f.size / (1024 * 1024)
            c1, c2, c3 = st.columns([5, 2, 2])
            c1.write(f"**{i}.** {f.name}")
            c2.caption(f"{mb:.1f} MB")
            c3.caption("ğŸ”§ è¦åœ§ç¸®" if mb > 24 else "âœ… OK")

    if material_files:
        st.info(f"ğŸ“ è£œè¶³è³‡æ–™ï¼ˆ{len(material_files)}ä»¶ï¼‰: {', '.join(f.name for f in material_files)}")
    else:
        st.caption("ğŸ“ è£œè¶³è³‡æ–™ãªã—")

    st.markdown("---")
    run = st.button("ğŸš€ å‡¦ç†é–‹å§‹", type="primary", use_container_width=True)

    if run:
        # è³‡æ–™ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
        combined_material = None
        if material_files:
            with st.spinner("ğŸ“„ è£œè¶³è³‡æ–™ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
                mat_texts = []
                for mf in material_files:
                    t = extract_material_text(mf)
                    if t and not t.startswith("["):
                        mat_texts.append(f"=== {mf.name} ===\n{t}")
                    else:
                        st.warning(f"âš ï¸ {mf.name}: {t}")
            if mat_texts:
                combined_material = "\n\n".join(mat_texts)
                st.success(f"âœ… è³‡æ–™ {len(mat_texts)}ä»¶ èª­ã¿è¾¼ã¿å®Œäº†")

        new_results = []
        for idx, audio_file in enumerate(sorted_audio):
            st.markdown(f"---")
            st.markdown(f"**[{idx+1}/{len(sorted_audio)}]** {audio_file.name}")

            result = {
                "filename": audio_file.name,
                "date": datetime.now().strftime("%Y-%m-%d %H:%M"),
                "transcript": None,
                "report": None,
                "summary_html": None,
                "has_material": combined_material is not None
            }

            suffix = Path(audio_file.name).suffix
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as f:
                f.write(audio_file.read())
                tmp_path = f.name

            try:
                # 1. æ–‡å­—èµ·ã“ã—
                with st.spinner("ğŸ§ æ–‡å­—èµ·ã“ã—ä¸­..."):
                    transcript = transcribe_audio(tmp_path, st.session_state.api_key)
                if not transcript:
                    st.error(f"âŒ æ–‡å­—èµ·ã“ã—å¤±æ•—")
                    continue
                result["transcript"] = transcript
                st.success(f"âœ… æ–‡å­—èµ·ã“ã—å®Œäº†ï¼ˆ{len(transcript):,}æ–‡å­—ï¼‰")

                # 2. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
                with st.spinner("ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­ (GPT-4o)..."):
                    report = generate_report(transcript, combined_material, st.session_state.api_key)
                if report:
                    result["report"] = report
                    st.success(f"âœ… ãƒ¬ãƒãƒ¼ãƒˆå®Œäº†{'ï¼ˆè³‡æ–™è£œå®Œã‚ã‚Šï¼‰' if combined_material else ''}")

                # 3. æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
                if report:
                    with st.spinner("ğŸ“‹ æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ç”Ÿæˆä¸­..."):
                        summary_data = generate_summary_json(
                            transcript, report, combined_material, st.session_state.api_key
                        )
                    if summary_data:
                        generated_at = datetime.now().strftime("%Y-%m-%d %H:%M")
                        result["summary_html"] = summary_to_html(
                            summary_data, audio_file.name, generated_at
                        )
                        st.success("âœ… æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼å®Œäº†")

            finally:
                if os.path.exists(tmp_path):
                    os.remove(tmp_path)

            new_results.append(result)

        st.session_state.results = new_results + st.session_state.results
        st.balloons()
        st.success(f"ğŸ‰ {len(new_results)}ä»¶ å‡¦ç†å®Œäº†ï¼")


# â”€â”€ çµæœè¡¨ç¤º â”€â”€
if st.session_state.results:
    st.markdown("---")
    st.header(f"ğŸ“‹ å‡¦ç†çµæœï¼ˆ{len(st.session_state.results)}ä»¶ï¼‰")

    for result in st.session_state.results:
        mat_badge = "  ğŸ“ è³‡æ–™è£œå®Œã‚ã‚Š" if result["has_material"] else ""
        with st.expander(
            f"ğŸ“ {result['filename']}  â€”  {result['date']}{mat_badge}",
            expanded=True
        ):
            tab_labels = ["ğŸ“„ æ–‡å­—èµ·ã“ã—", "ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆ"]
            if result.get("summary_html"):
                tab_labels.append("ğŸ“‹ æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼")
            tabs = st.tabs(tab_labels)

            # æ–‡å­—èµ·ã“ã—
            with tabs[0]:
                if result["transcript"]:
                    st.text_area("", result["transcript"], height=250,
                                 key=f"tr_{result['filename']}_{result['date']}")
                    st.download_button(
                        "ğŸ“¥ æ–‡å­—èµ·ã“ã— (.txt)",
                        result["transcript"],
                        file_name=f"transcript_{Path(result['filename']).stem}.txt",
                        mime="text/plain",
                        key=f"dtr_{result['filename']}_{result['date']}"
                    )

            # ãƒ¬ãƒãƒ¼ãƒˆ
            with tabs[1]:
                if result["report"]:
                    st.markdown(result["report"])
                    st.download_button(
                        "ğŸ“¥ ãƒ¬ãƒãƒ¼ãƒˆ (.md)",
                        result["report"],
                        file_name=f"report_{Path(result['filename']).stem}.md",
                        mime="text/markdown",
                        key=f"drp_{result['filename']}_{result['date']}"
                    )

            # æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼
            if result.get("summary_html") and len(tabs) > 2:
                with tabs[2]:
                    st.info("ğŸ’¡ ã€ŒHTMLã§ä¿å­˜ã€ã—ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã§é–‹ãã¨ã€è¦‹ã‚„ã™ãå°åˆ·ã§ãã¾ã™ã€‚")
                    st.download_button(
                        "ğŸ“¥ æ§‹é€ åŒ–ã‚µãƒãƒªãƒ¼ HTML (.html)",
                        result["summary_html"],
                        file_name=f"summary_{Path(result['filename']).stem}.html",
                        mime="text/html",
                        key=f"dsum_{result['filename']}_{result['date']}"
                    )
                    # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰
                    with st.expander("ğŸ” ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆã‚¢ãƒ—ãƒªå†…ï¼‰"):
                        st.components.v1.html(result["summary_html"], height=800, scrolling=True)

st.markdown("---")
st.caption("ğŸ™ï¸ éŸ³å£°ãƒ¡ãƒ¢ã‚¢ãƒ—ãƒª Pro ï¼ Powered by OpenAI Whisper & GPT-4o")
