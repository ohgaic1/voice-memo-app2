import streamlit as st
import tempfile
import os
from pathlib import Path
import subprocess
from openai import OpenAI
import json
from datetime import datetime

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="éŸ³å£°ãƒ¡ãƒ¢ã‚¢ãƒ—ãƒªï¼ˆé«˜å“è³ªç‰ˆï¼‰",
    page_icon="ğŸ™ï¸",
    layout="wide"
)

# OpenAI APIã‚­ãƒ¼ã®è¨­å®š
if "OPENAI_API_KEY" not in st.session_state:
    st.session_state.OPENAI_API_KEY = ""

def compress_audio(input_path, output_path, target_bitrate="32k"):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åœ§ç¸®"""
    try:
        cmd = [
            "ffmpeg", "-i", input_path,
            "-vn",  # æ˜ åƒã‚’é™¤å¤–
            "-ac", "1",  # ãƒ¢ãƒãƒ©ãƒ«
            "-ar", "16000",  # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ16kHz
            "-b:a", target_bitrate,
            "-y",  # ä¸Šæ›¸ã
            output_path
        ]
        subprocess.run(cmd, check=True, capture_output=True)
        return True
    except subprocess.CalledProcessError as e:
        st.error(f"åœ§ç¸®ã‚¨ãƒ©ãƒ¼: {e.stderr.decode()}")
        return False
    except FileNotFoundError:
        st.error("ffmpegãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return False

def split_audio(input_path, chunk_duration=600):
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šç§’æ•°ã”ã¨ã«åˆ†å‰²ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ10åˆ†ï¼‰"""
    chunks = []
    try:
        # éŸ³å£°ã®é•·ã•ã‚’å–å¾—
        probe_cmd = [
            "ffprobe", "-v", "error",
            "-show_entries", "format=duration",
            "-of", "default=noprint_wrappers=1:nokey=1",
            input_path
        ]
        result = subprocess.run(probe_cmd, capture_output=True, text=True, check=True)
        duration = float(result.stdout.strip())
        
        # ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
        num_chunks = int(duration / chunk_duration) + 1
        
        for i in range(num_chunks):
            start_time = i * chunk_duration
            chunk_path = input_path.replace(".mp3", f"_chunk_{i}.mp3")
            
            split_cmd = [
                "ffmpeg", "-i", input_path,
                "-ss", str(start_time),
                "-t", str(chunk_duration),
                "-c", "copy",
                "-y",
                chunk_path
            ]
            subprocess.run(split_cmd, check=True, capture_output=True)
            chunks.append(chunk_path)
        
        return chunks
    except Exception as e:
        st.error(f"åˆ†å‰²ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return []

def transcribe_audio(file_path, api_key):
    """OpenAI Whisper APIã§æ–‡å­—èµ·ã“ã—"""
    client = OpenAI(api_key=api_key)
    
    file_size = os.path.getsize(file_path)
    max_size = 24 * 1024 * 1024  # 24MB (ä½™è£•ã‚’æŒã£ã¦)
    
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        if file_size > max_size:
            st.info("ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤§ãã„ãŸã‚ã€åœ§ç¸®å‡¦ç†ã‚’è¡Œã„ã¾ã™...")
            
            # åœ§ç¸®
            compressed_path = file_path.replace(".mp3", "_compressed.mp3")
            if not compress_audio(file_path, compressed_path):
                return None
            
            # åœ§ç¸®å¾Œã‚‚ã‚µã‚¤ã‚ºã‚ªãƒ¼ãƒãƒ¼ãªã‚‰åˆ†å‰²
            if os.path.getsize(compressed_path) > max_size:
                st.info("åœ§ç¸®å¾Œã‚‚ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤§ãã„ãŸã‚ã€åˆ†å‰²å‡¦ç†ã‚’è¡Œã„ã¾ã™...")
                chunks = split_audio(compressed_path)
                
                if not chunks:
                    return None
                
                # å„ãƒãƒ£ãƒ³ã‚¯ã‚’æ–‡å­—èµ·ã“ã—
                full_transcript = ""
                progress_bar = st.progress(0)
                
                for idx, chunk_path in enumerate(chunks):
                    with open(chunk_path, "rb") as audio_file:
                        transcript = client.audio.transcriptions.create(
                            model="whisper-1",
                            file=audio_file,
                            language="ja"
                        )
                        full_transcript += transcript.text + " "
                    
                    progress_bar.progress((idx + 1) / len(chunks))
                    
                    # ãƒãƒ£ãƒ³ã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    os.remove(chunk_path)
                
                os.remove(compressed_path)
                return full_transcript.strip()
            else:
                # åœ§ç¸®ç‰ˆã‚’ä½¿ç”¨
                with open(compressed_path, "rb") as audio_file:
                    transcript = client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio_file,
                        language="ja"
                    )
                os.remove(compressed_path)
                return transcript.text
        else:
            # é€šå¸¸ã®æ–‡å­—èµ·ã“ã—
            with open(file_path, "rb") as audio_file:
                transcript = client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="ja"
                )
                return transcript.text
                
    except Exception as e:
        st.error(f"æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

def generate_plaud_style_report(transcript, api_key):
    """Plaudé¢¨ã®è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    client = OpenAI(api_key=api_key)
    
    prompt = f"""ä»¥ä¸‹ã®éŸ³å£°æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€è©³ç´°ã§æ§‹é€ åŒ–ã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ:
{transcript}

ä»¥ä¸‹ã®å½¢å¼ã§ã€ã§ãã‚‹ã ã‘è©³ç´°ã‹ã¤å…·ä½“çš„ã«ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„:

# ğŸ“ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼
ï¼ˆ2-3æ®µè½ã§å…¨ä½“ã®æ ¸å¿ƒã‚’è¦ç´„ã€‚å˜ãªã‚‹æ¦‚è¦ã§ã¯ãªãã€æœ€ã‚‚é‡è¦ãªæ´å¯Ÿã‚„çµè«–ã‚’å«ã‚ã‚‹ï¼‰

# ğŸ¯ ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆ
ï¼ˆ5-10å€‹ã®é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã‚’ç®‡æ¡æ›¸ãã€‚å„ãƒã‚¤ãƒ³ãƒˆã¯å…·ä½“çš„ã§ã€æ–‡è„ˆã‚’å«ã‚ã‚‹ï¼‰

# ğŸ’¡ ä¸»è¦ãªæ´å¯Ÿã¨åˆ†æ
ï¼ˆ3-5å€‹ã®æ·±ã„æ´å¯Ÿã€‚ãªãœé‡è¦ã‹ã€ã©ã®ã‚ˆã†ãªæ„å‘³ã‚’æŒã¤ã‹ã‚’èª¬æ˜ï¼‰

# âœ… ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ 
ï¼ˆå®Ÿè¡Œå¯èƒ½ãªå…·ä½“çš„ãªã‚¿ã‚¹ã‚¯ã‚’å„ªå…ˆåº¦ä»˜ãã§åˆ—æŒ™ã€‚èª°ãŒã€ä½•ã‚’ã€ã„ã¤ã¾ã§ã«ã‚’æ˜ç¢ºã«ï¼‰

# ğŸ—£ï¸ é‡è¦ãªç™ºè¨€ãƒ»å¼•ç”¨
ï¼ˆç‰¹ã«å°è±¡çš„ã¾ãŸã¯é‡è¦ãªç™ºè¨€ã‚’3-5å€‹æŠœç²‹ã€‚æ–‡è„ˆã¨å…±ã«ï¼‰

# ğŸ“Š ãƒˆãƒ”ãƒƒã‚¯åˆ¥è©³ç´°åˆ†æ
ï¼ˆä¸»è¦ãªãƒˆãƒ”ãƒƒã‚¯ã”ã¨ã«è©³ã—ãåˆ†æã€‚å„ãƒˆãƒ”ãƒƒã‚¯ã§è­°è«–ã•ã‚ŒãŸå†…å®¹ã€æ±ºå®šäº‹é …ã€æ‡¸å¿µç‚¹ãªã©ï¼‰

# ğŸ”„ ãƒ•ã‚©ãƒ­ãƒ¼ã‚¢ãƒƒãƒ—äº‹é …
ï¼ˆä»Šå¾Œã®ç¢ºèªäº‹é …ã€æœªè§£æ±ºã®å•é¡Œã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼‰

# ğŸ“Œ ãƒ¡ã‚¿æƒ…å ±
- æ¨å®šæ‰€è¦æ™‚é–“: [Xåˆ†]
- ä¸»è¦å‚åŠ è€…/è©±è€…: [æ¨å®š]
- ä¼šè­°/ãƒ¡ãƒ¢ã®ã‚¿ã‚¤ãƒ—: [æ¨å®šï¼šä¼šè­°ã€ãƒ–ãƒ¬ã‚¹ãƒˆã€1on1ãªã©]
- ç·Šæ€¥åº¦: [é«˜/ä¸­/ä½]

æ³¨æ„äº‹é …:
- æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å…·ä½“çš„ãªæƒ…å ±ã‚’æŠ½å‡ºã—ã€æƒ³åƒã‚„ä¸€èˆ¬è«–ã¯é¿ã‘ã‚‹
- å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯è©³ç´°ã«è¨˜è¿°ã—ã€å˜ãªã‚‹ç®‡æ¡æ›¸ãã ã‘ã§ãªãèª¬æ˜ã‚‚åŠ ãˆã‚‹
- å®Ÿéš›ã®å†…å®¹ã«åŸºã¥ã„ã¦ã€æœ‰ç”¨ã§å®Ÿè·µçš„ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹
- æ–‡å­—èµ·ã“ã—ã«å«ã¾ã‚Œãªã„æƒ…å ±ã¯æ¨æ¸¬ã›ãšã€ã€Œè¨€åŠãªã—ã€ã¨è¨˜è¼‰ã™ã‚‹
"""

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ã‚ãªãŸã¯éŸ³å£°ãƒ¡ãƒ¢ã‹ã‚‰é«˜å“è³ªãªæ§‹é€ åŒ–ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚Plaudã‚¢ãƒ—ãƒªã®ã‚ˆã†ãªã€è©³ç´°ã§å®Ÿç”¨çš„ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        st.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¨ãƒ©ãƒ¼: {str(e)}")
        return None

# ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒª
st.title("ğŸ™ï¸ éŸ³å£°ãƒ¡ãƒ¢ã‚¢ãƒ—ãƒªï¼ˆé«˜å“è³ªç‰ˆï¼‰")
st.markdown("**å¤§å®¹é‡å¯¾å¿œ + Plaudé¢¨è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ**")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š")
    
    api_key = st.text_input(
        "OpenAI APIã‚­ãƒ¼",
        type="password",
        value=st.session_state.OPENAI_API_KEY,
        help="OpenAIã®APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„"
    )
    
    if api_key:
        st.session_state.OPENAI_API_KEY = api_key
        st.success("âœ“ APIã‚­ãƒ¼è¨­å®šæ¸ˆã¿")
    
    st.markdown("---")
    st.markdown("### ğŸ“– ä½¿ã„æ–¹")
    st.markdown("""
    1. OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›
    2. éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    3. è‡ªå‹•ã§æ–‡å­—èµ·ã“ã—ï¼†ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    
    **å¯¾å¿œå½¢å¼**: MP3, WAV, M4A, WebM
    
    **ç‰¹å¾´**:
    - ğŸ”Š å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œï¼ˆè‡ªå‹•åœ§ç¸®ãƒ»åˆ†å‰²ï¼‰
    - ğŸ“ Plaudé¢¨ã®è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
    - âš¡ GPT-4oä½¿ç”¨ã§é«˜å“è³ª
    """)
    
    st.markdown("---")
    st.markdown("### ğŸ’¡ ãƒ’ãƒ³ãƒˆ")
    st.markdown("""
    - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™ãªã—
    - é•·æ™‚é–“éŒ²éŸ³ã‚‚è‡ªå‹•å‡¦ç†
    - æ—¥æœ¬èªã«æœ€é©åŒ–
    """)

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
if not st.session_state.OPENAI_API_KEY:
    st.warning("âš ï¸ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§OpenAI APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
    st.info("APIã‚­ãƒ¼ã¯ [OpenAI Platform](https://platform.openai.com/api-keys) ã§å–å¾—ã§ãã¾ã™")
else:
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_file = st.file_uploader(
        "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=["mp3", "wav", "m4a", "webm"],
        help="MP3, WAV, M4A, WebMå½¢å¼ã«å¯¾å¿œã€‚å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚è‡ªå‹•å‡¦ç†ã—ã¾ã™ã€‚"
    )
    
    if uploaded_file:
        # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤º
        file_size_mb = uploaded_file.size / (1024 * 1024)
        st.info(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file.name} ({file_size_mb:.2f} MB)")
        
        if st.button("ğŸš€ æ–‡å­—èµ·ã“ã—ï¼†ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ", type="primary"):
            with st.spinner("å‡¦ç†ä¸­..."):
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                    tmp_file.write(uploaded_file.read())
                    tmp_path = tmp_file.name
                
                try:
                    # æ–‡å­—èµ·ã“ã—
                    st.info("ğŸ§ éŸ³å£°ã‚’æ–‡å­—èµ·ã“ã—ä¸­...")
                    transcript = transcribe_audio(tmp_path, st.session_state.OPENAI_API_KEY)
                    
                    if transcript:
                        st.success("âœ“ æ–‡å­—èµ·ã“ã—å®Œäº†")
                        
                        # æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º
                        with st.expander("ğŸ“„ æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆï¼ˆã‚¯ãƒªãƒƒã‚¯ã§è¡¨ç¤ºï¼‰"):
                            st.text_area("", transcript, height=300)
                        
                        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
                        st.info("ğŸ“Š è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­...")
                        report = generate_plaud_style_report(transcript, st.session_state.OPENAI_API_KEY)
                        
                        if report:
                            st.success("âœ“ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†")
                            
                            # ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
                            st.markdown("---")
                            st.markdown("## ğŸ“‹ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ")
                            st.markdown(report)
                            
                            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                            col1, col2 = st.columns(2)
                            
                            with col1:
                                st.download_button(
                                    "ğŸ“¥ æ–‡å­—èµ·ã“ã—ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                    transcript,
                                    file_name=f"transcript_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
                                    mime="text/plain"
                                )
                            
                            with col2:
                                st.download_button(
                                    "ğŸ“¥ ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                    report,
                                    file_name=f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
                                    mime="text/markdown"
                                )
                    
                finally:
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                    if os.path.exists(tmp_path):
                        os.remove(tmp_path)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: #666; font-size: 0.9em;'>
    <p>ğŸ™ï¸ éŸ³å£°ãƒ¡ãƒ¢ã‚¢ãƒ—ãƒªï¼ˆé«˜å“è³ªç‰ˆï¼‰| Powered by OpenAI Whisper & GPT-4o</p>
</div>
""", unsafe_allow_html=True)
